{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40730f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zauch\\Documents\\GIT\\cropRecommendation\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\zauch\\Documents\\GIT\\cropRecommendation\\.venv\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [12:37:30] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost's Accuracy: 98.64%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       apple       1.00      1.00      1.00        23\n",
      "      banana       1.00      1.00      1.00        21\n",
      "   blackgram       0.95      1.00      0.98        20\n",
      "    chickpea       1.00      1.00      1.00        26\n",
      "     coconut       1.00      1.00      1.00        27\n",
      "      coffee       1.00      1.00      1.00        17\n",
      "      cotton       0.94      1.00      0.97        17\n",
      "      grapes       1.00      1.00      1.00        14\n",
      "        jute       0.96      0.96      0.96        23\n",
      " kidneybeans       1.00      1.00      1.00        20\n",
      "      lentil       0.92      1.00      0.96        11\n",
      "       maize       1.00      0.95      0.98        21\n",
      "       mango       0.95      1.00      0.97        19\n",
      "   mothbeans       1.00      0.96      0.98        24\n",
      "    mungbean       1.00      1.00      1.00        19\n",
      "   muskmelon       1.00      1.00      1.00        17\n",
      "      orange       1.00      1.00      1.00        14\n",
      "      papaya       1.00      1.00      1.00        23\n",
      "  pigeonpeas       1.00      0.91      0.95        23\n",
      " pomegranate       1.00      1.00      1.00        23\n",
      "        rice       0.95      0.95      0.95        19\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       440\n",
      "   macro avg       0.98      0.99      0.99       440\n",
      "weighted avg       0.99      0.99      0.99       440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importieren der notwendigen Bibliotheken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "acc = []\n",
    "model = []\n",
    "\n",
    "# Laden des Datensatzes\n",
    "file_path = 'Crop_recommendation.csv'  # Stellen Sie sicher, dass sich die Datei im gleichen Verzeichnis befindet\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#sns.heatmap(data.corr(),annot=True)\n",
    "\n",
    "# Features und Zielvariable definieren\n",
    "X = data[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "y = data['label']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Trainings- und Testdaten aufteilen\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost-Modell initialisieren und trainieren\n",
    "XB = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "XB.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "predicted_values = XB.predict(X_test)\n",
    "\n",
    "# Genauigkeit und Bericht\n",
    "accuracy = accuracy_score(y_test, predicted_values)\n",
    "print(f\"XGBoost's Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, predicted_values, target_names=label_encoder.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d37a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|===================| 9566/9680 [00:33<00:00]        "
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Globale Analyse\u001b[39;00m\n\u001b[0;32m      8\u001b[0m shap_values_aggregated \u001b[38;5;241m=\u001b[39m shap_values\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# SHAP-Werte über Klassen mitteln\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values_aggregated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Lokale Analyse\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sample_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Beispiel-Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zauch\\Documents\\GIT\\cropRecommendation\\.venv\\Lib\\site-packages\\shap\\plots\\_beeswarm.py:543\u001b[0m, in \u001b[0;36msummary_legacy\u001b[1;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    541\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 543\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    546\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[1;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    }
   ],
   "source": [
    "# SHAP-Explainer erstellen\n",
    "explainer = shap.Explainer(XB, X_train)\n",
    "\n",
    "# SHAP-Werte berechnen\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Struktur der SHAP-Werte prüfen\n",
    "print(f\"SHAP Values Shape: {shap_values.values.shape}\")\n",
    "\n",
    "# Globale Analyse: SHAP-Werte über Klassen aggregieren\n",
    "shap_values_aggregated = shap_values.values.mean(axis=1)  # Durchschnitt über Klassen\n",
    "shap.summary_plot(shap_values_aggregated, X_test, feature_names=X.columns)\n",
    "\n",
    "# Lokale Analyse: SHAP-Werte für eine spezifische Klasse\n",
    "sample_idx = 0  # Beispiel-Index\n",
    "class_idx = 0   # Index der Klasse\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[class_idx],          # Erwartungswert der Klasse\n",
    "    shap_values.values[sample_idx, class_idx, :], # SHAP-Werte für diese Klasse\n",
    "    X_test.iloc[sample_idx, :]                    # Eingabemerkmale\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
